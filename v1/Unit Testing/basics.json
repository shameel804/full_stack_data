[
    {
        "q": "What is the primary goal of unit testing?",
        "o": [
            "To verify individual components work in isolation",
            "To test the entire application workflow",
            "To find security vulnerabilities",
            "To check database connections"
        ]
    },
    {
        "q": "Which of the following is NOT a characteristic of a good unit test?",
        "o": [
            "Dependent on external systems",
            "Fast execution",
            "Deterministic results",
            "Isolated from other tests"
        ]
    },
    {
        "q": "What does a unit test typically assert?",
        "o": [
            "The actual output matches the expected output",
            "The code compiles without errors",
            "The user interface looks correct",
            "The database schema is valid"
        ]
    },
    {
        "q": "In unit testing, what is a 'fixture'?",
        "o": [
            "A fixed state used as a baseline for running tests",
            "A bug found during testing",
            "A tool for running tests",
            "A type of assertion"
        ]
    },
    {
        "q": "What is the 'AAA' pattern in unit testing?",
        "o": [
            "Arrange, Act, Assert",
            "Apply, Analyze, Accept",
            "Automate, Assess, Approve",
            "Assemble, Activate, Audit"
        ]
    },
    {
        "q": "What follows the 'Arrange' step in the AAA pattern?",
        "o": [
            "Act",
            "Assert",
            "Analyze",
            "Apply"
        ]
    },
    {
        "q": "Which step in AAA involves invoking the method under test?",
        "o": [
            "Act",
            "Arrange",
            "Assert",
            "After"
        ]
    },
    {
        "q": "What is the purpose of the 'Assert' step in AAA?",
        "o": [
            "To verify the result of the action",
            "To set up the test data",
            "To execute the code",
            "To clean up resources"
        ]
    },
    {
        "q": "What is a 'test case'?",
        "o": [
            "A set of conditions and expected results for a test",
            "A tool used to run tests",
            "A report of test failures",
            "A specific line of code to test"
        ]
    },
    {
        "q": "What is 'setup' code in a test suite?",
        "o": [
            "Code that runs before each test to prepare the environment",
            "Code that runs after each test to clean up",
            "Code that asserts the results",
            "Code that compiles the application"
        ]
    },
    {
        "q": "What is 'teardown' code in a test suite?",
        "o": [
            "Code that runs after tests to clean up resources",
            "Code that runs before tests to initialize data",
            "Code that defines the test runner",
            "Code that reports test coverage"
        ]
    },
    {
        "q": "Why should unit tests be independent of each other?",
        "o": [
            "To ensure one test failure doesn't affect others",
            "To reduce the code size",
            "To make them run slower",
            "To allow them to share variables"
        ]
    },
    {
        "q": "What is a 'mock' object?",
        "o": [
            "A simulated object that mimics the behavior of a real one",
            "A real database connection",
            "A copy of the production code",
            "A tool for writing documentation"
        ]
    },
    {
        "q": "True or False: Unit tests should access the production database.",
        "o": [
            "False",
            "True",
            "Sometimes",
            "Only for read operations"
        ]
    },
    {
        "q": "What is 'test coverage'?",
        "o": [
            "A measure of how much code is executed by tests",
            "The number of tests written",
            "The time it takes to run tests",
            "The number of developers writing tests"
        ]
    },
    {
        "q": "Which of these is a valid assertion?",
        "o": [
            "expect(value).toBe(5)",
            "print(value)",
            "run(value)",
            "calculate(value)"
        ]
    },
    {
        "q": "What does 'expect(true).toBe(false)' typically result in?",
        "o": [
            "A failed test",
            "A passed test",
            "A warning",
            "A syntax error"
        ]
    },
    {
        "q": "Ideally, how many logical assertions should a unit test have?",
        "o": [
            "One logical assertion per test",
            "As many as possible",
            "Zero",
            "Between 10 and 20"
        ]
    },
    {
        "q": "What does SUT stand for in testing context?",
        "o": [
            "System Under Test",
            "Standard Unit Test",
            "Simple User Task",
            "Software Utility Tool"
        ]
    },
    {
        "q": "What is 'regression testing'?",
        "o": [
            "Testing to ensure changes didn't break existing functionality",
            "Testing new features only",
            "Testing the user interface design",
            "Testing the database performance"
        ]
    },
    {
        "q": "How often should unit tests be run?",
        "o": [
            "Frequently, ideally after every code change",
            "Once a week",
            "Only before release",
            "Once a month"
        ]
    },
    {
        "q": "What is 'Red-Green-Refactor'?",
        "o": [
            "A cycle for Test-Driven Development",
            "A method for color-coding logs",
            "A design pattern for UI",
            "A database optimization technique"
        ]
    },
    {
        "q": "In TDD, what does 'Red' mean?",
        "o": [
            "Write a failing test",
            "Write passing code",
            "Refactor the code",
            "Delete the test"
        ]
    },
    {
        "q": "In TDD, what does 'Green' mean?",
        "o": [
            "Write just enough code to pass the test",
            "Write a failing test",
            "Optimize the code",
            "Deploy to production"
        ]
    },
    {
        "q": "Which framework is commonly used for JavaScript unit testing?",
        "o": [
            "Jest",
            "Django",
            "Flutter",
            "Laravel"
        ]
    },
    {
        "q": "What is a 'stub' in testing?",
        "o": [
            "A dummy component that returns hard-coded values",
            "A real implementation of a service",
            "A type of assertion error",
            "A failing test case"
        ]
    },
    {
        "q": "What describes 'white-box' testing?",
        "o": [
            "Testing with knowledge of internal implementation",
            "Testing only user interfaces",
            "Testing without knowing the code",
            "Testing network speeds"
        ]
    },
    {
        "q": "What describes 'black-box' testing?",
        "o": [
            "Testing functionality without seeing internal code",
            "Testing code logic directly",
            "Testing database schemas",
            "Testing variable names"
        ]
    },
    {
        "q": "Is unit testing usually white-box or black-box?",
        "o": [
            "Mostly white-box",
            "Strictly black-box",
            "Always grey-box",
            "Blue-box"
        ]
    },
    {
        "q": "What is a 'flaky' test?",
        "o": [
            "A test that sometimes passes and sometimes fails without code changes",
            "A test that always fails",
            "A test that is too slow",
            "A test that checks nothing"
        ]
    },
    {
        "q": "What is a common cause of flaky tests?",
        "o": [
            "Dependency on external systems or time",
            "Pure functions",
            "Immutable data",
            "Static typing"
        ]
    },
    {
        "q": "What is the benefit of naming tests clearly?",
        "o": [
            "It acts as documentation and makes debugging easier",
            "It makes the code run faster",
            "It reduces compilation time",
            "It automatically fixes bugs"
        ]
    },
    {
        "q": "What does the assertion 'assertNotNull(obj)' check?",
        "o": [
            "That 'obj' is not null",
            "That 'obj' is null",
            "That 'obj' is a string",
            "That 'obj' is undefined"
        ]
    },
    {
        "q": "What is the output of this assertion?",
        "c": "let x = 10;\nlet y = 10;\nassert(x == y);",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Indeterminate"
        ]
    },
    {
        "q": "What is the output of this assertion?",
        "c": "let list = [];\nassert(list.length > 0);",
        "o": [
            "Fail",
            "Pass",
            "Warning",
            "Skip"
        ]
    },
    {
        "q": "Which function is typically used for cleanup after all tests?",
        "o": [
            "afterAll()",
            "beforeAll()",
            "beforeEach()",
            "test()"
        ]
    },
    {
        "q": "Which function runs before every single test case?",
        "o": [
            "beforeEach()",
            "beforeAll()",
            "afterAll()",
            "describe()"
        ]
    },
    {
        "q": "What is the purpose of grouping tests with 'describe'?",
        "o": [
            "To organize related tests into a suite",
            "To run tests faster",
            "To skip tests",
            "To automatically fix tests"
        ]
    },
    {
        "q": "What happens if an assertion fails in a test?",
        "o": [
            "The test is marked as failed and execution typically stops for that test",
            "The test continues and logs a warning",
            "The program crashes immediately",
            "The testing framework deletes the code"
        ]
    },
    {
        "q": "What is 'mutation testing'?",
        "o": [
            "Modifying code slightly to see if tests catch the change",
            "Changing test names randomly",
            "Running tests on different OS",
            "Testing expected mutations in data"
        ]
    },
    {
        "q": "Why avoid logic inside unit tests?",
        "o": [
            "It increases the chance of bugs in the test itself",
            "It makes tests run faster",
            "It is required by all frameworks",
            "It simplifies the assertions"
        ]
    },
    {
        "q": "What is a 'happy path' test?",
        "o": [
            "Testing the expected, error-free usage scenario",
            "Testing error conditions",
            "Testing boundary values",
            "Testing meaningful UI colors"
        ]
    },
    {
        "q": "What is an 'edge case' test?",
        "o": [
            "Testing extreme or boundary conditions",
            "Testing the default flow",
            "Testing average inputs",
            "Testing the happy path"
        ]
    },
    {
        "q": "What is the output of this test code?",
        "c": "test('math', () => {\n  expect(2 + 2).toBe(4);\n});",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Timeout"
        ]
    },
    {
        "q": "What is the output of this test code?",
        "c": "test('math', () => {\n  expect(2 + 2).not.toBe(5);\n});",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Timeout"
        ]
    },
    {
        "q": "When should you mock a dependency?",
        "o": [
            "When it is slow, unreliable, or external (e.g., API, DB)",
            "Always",
            "Never",
            "Only for primitive types"
        ]
    },
    {
        "q": "What is 'parameterized testing'?",
        "o": [
            "Running the same test logic with different input values",
            "Running tests in parallel",
            "Testing identifying parameters of functions",
            "Hardcoding parameters in tests"
        ]
    },
    {
        "q": "Why is 'hardcoding' expected values in tests good?",
        "o": [
            "It ensures the test verifies specific, known outcomes",
            "It makes the code flexible",
            "It allows dynamic results",
            "It reduces test file size"
        ]
    },
    {
        "q": "What does a 'spy' do in testing?",
        "o": [
            "Tracks calls to a function and its arguments",
            "Encrypts test data",
            "Deletes function code",
            "Renames functions"
        ]
    },
    {
        "q": "True or False: Integration tests are the same as unit tests.",
        "o": [
            "False",
            "True",
            "Depends on the language",
            "They are identical"
        ]
    },
    {
        "q": "What is the main focus of integration tests vs unit tests?",
        "o": [
            "Interaction between modules vs isolation of a module",
            "Speed vs cost",
            "Frontend vs backend",
            "Styles vs Logic"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "function add(a, b) { return a + b; }\n// Test\nif (add(1, 1) === 3) console.log('Pass');\nelse console.log('Fail');",
        "o": [
            "Fail",
            "Pass",
            "Error",
            "3"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "function isEven(n) { return n % 2 === 0; }\n// Test\nconsole.log(isEven(4));",
        "o": [
            "true",
            "false",
            "undefined",
            "Error"
        ]
    },
    {
        "q": "Which assertion checks if two references point to the same object?",
        "o": [
            "assertSame / toBe",
            "assertEqual / toEqual",
            "assertNull",
            "assertTrue"
        ]
    },
    {
        "q": "Which assertion checks if two objects have the same content?",
        "o": [
            "assertEqual / toEqual",
            "assertSame",
            "assertCheck",
            "expectReference"
        ]
    },
    {
        "q": "What is 'Negative Testing'?",
        "o": [
            "Testing that the system handles invalid input gracefully",
            "Testing with negative numbers only",
            "Testing meant to fail the build",
            "Removing tests"
        ]
    },
    {
        "q": "Where should unit test files typically be located?",
        "o": [
            "Close to the source code or in a 'tests' directory",
            "In the 'node_modules' folder",
            "On the desktop",
            "In the database"
        ]
    },
    {
        "q": "What is a 'smoke test'?",
        "o": [
            "A quick check to ensure critical functions work",
            "A thorough regression test",
            "A test for firewalls",
            "A test that runs for hours"
        ]
    },
    {
        "q": "Does unit testing guarantee bug-free code?",
        "o": [
            "No, it only reduces bugs and improves design",
            "Yes, 100%",
            "Yes, if coverage is 100%",
            "Yes, for small apps"
        ]
    },
    {
        "q": "What is 'code smell' in the context of tests?",
        "o": [
            "Poorly structured test code indicating issues",
            "Tests that pass",
            "Comments in tests",
            "Fast tests"
        ]
    },
    {
        "q": "Which is a sign of a bad unit test?",
        "o": [
            "It requires a specific execution order",
            "It is small",
            "It tests one thing",
            "It is easy to read"
        ]
    },
    {
        "q": "What does CI stand for in testing context?",
        "o": [
            "Continuous Integration",
            "Common Interface",
            "Code Inspector",
            "Command Interpretor"
        ]
    },
    {
        "q": "How does CI relate to unit testing?",
        "o": [
            "CI servers automatically run unit tests on commit",
            "CI writes the tests",
            "CI deletes failed tests",
            "They are unrelated"
        ]
    },
    {
        "q": "What is 'Code Coverage' percentage?",
        "o": [
            "Percentage of code lines executed by tests",
            "Percentage of correct tests",
            "Percentage of comments in code",
            "Percentage of assertions"
        ]
    },
    {
        "q": "What is a good target for code coverage?",
        "o": [
            "80% or higher is often cited, but depends on context",
            "10%",
            "100% always",
            "50%"
        ]
    },
    {
        "q": "Can you have 100% coverage and still have bugs?",
        "o": [
            "Yes, logic errors can still exist",
            "No, 100% means perfect",
            "Only if tests are written in Java",
            "No, impossible"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "// Test\nexpect([1, 2, 3]).toContain(2);",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Undefined"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "// Test\nexpect('hello').toBe('world');",
        "o": [
            "Fail",
            "Pass",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'Arrange' in: let x=1; x++; expect(x).toBe(2)?",
        "o": [
            "let x=1;",
            "x++;",
            "expect(x).toBe(2)",
            "None"
        ]
    },
    {
        "q": "What is 'Act' in: let x=1; x++; expect(x).toBe(2)?",
        "o": [
            "x++;",
            "let x=1;",
            "expect(x).toBe(2)",
            "None"
        ]
    },
    {
        "q": "What is 'Assert' in: let x=1; x++; expect(x).toBe(2)?",
        "o": [
            "expect(x).toBe(2)",
            "let x=1;",
            "x++;",
            "None"
        ]
    },
    {
        "q": "What is the purpose of 'beforeEach' vs 'beforeAll'?",
        "o": [
            "Reset state between tests vs set up once for suite",
            "Reset state once vs reset every time",
            "They are synonyms",
            "One is for async, one for sync"
        ]
    },
    {
        "q": "If a test fails, what should be the first step?",
        "o": [
            "Read the error message and identify the cause",
            "Delete the test",
            "Change the code to match the test result",
            "Restart the computer"
        ]
    },
    {
        "q": "What is 'Snapshot Testing'?",
        "o": [
            "Comparing current output against a stored reference file",
            "Taking a photo of the screen",
            "Testing valid snapshots of database",
            "Testing only UI components"
        ]
    },
    {
        "q": "When is Snapshot Testing useful?",
        "o": [
            "Ensuring UI or large data structures don't change unexpectedly",
            "Testing math calculations",
            "Testing loop logic",
            "Testing boolean flags"
        ]
    },
    {
        "q": "What happens if a Snapshot Test fails?",
        "o": [
            "You inspect the difference; verify if it's a bug or update the snapshot",
            "The build is broken forever",
            "The code is automatically reverted",
            "The snapshot deletes itself"
        ]
    },
    {
        "q": "What is the role of assertions library (e.g., Chai)?",
        "o": [
            "Provides readable methods to check conditions",
            "Compiles the code",
            "Runs the tests",
            "Generates documentation"
        ]
    },
    {
        "q": "What is the difference between 'toBe' and 'toEqual' in many frameworks?",
        "o": [
            "Identity vs value equality (deep check)",
            "They are always the same",
            "String vs Number check",
            "Sync vs Async check"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "let obj = { a: 1 };\n// Test\nexpect(obj).toEqual({ a: 1 });",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Undefined"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "let obj = { a: 1 };\n// Test assuming toBe checks reference\nexpect(obj).toBe({ a: 1 });",
        "o": [
            "Fail",
            "Pass",
            "Error",
            "Undefined"
        ]
    },
    {
        "q": "Can private methods be unit tested?",
        "o": [
            "Generally discouraged; test through public interface",
            "Yes, always required",
            "No, impossible",
            "Only in Python"
        ]
    },
    {
        "q": "What is a 'dummy' object in testing?",
        "o": [
            "Object passed around but never actually used (filler)",
            "A smart object",
            "A real object",
            "A faulty object"
        ]
    },
    {
        "q": "What is a 'spy' capable of recording?",
        "o": [
            "Number of invocations and arguments passed",
            "Memory usage",
            "CPU temperature",
            "Network latency"
        ]
    },
    {
        "q": "What describes 'Exploratory Testing'?",
        "o": [
            "Manual, unscripted investigation of the system",
            "Automated unit tests",
            "Running scripts",
            "Checking documentation"
        ]
    },
    {
        "q": "Is Exploratory Testing a type of Unit Testing?",
        "o": [
            "No, it is a manual testing approach",
            "Yes",
            "Partially",
            "Only in agile"
        ]
    },
    {
        "q": "What is the term for tests that run very slowly?",
        "o": [
            "Slow tests (often a sign they are not unit tests)",
            "Deep tests",
            "Thorough tests",
            "Good tests"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const sum = (a, b) => a + b;\n// Test\nif (sum(2, 3) === 5) throw new Error('Fail');",
        "o": [
            "Error: Fail",
            "Pass",
            "Nothing",
            "5"
        ]
    },
    {
        "q": "Ideally, tests should be...",
        "o": [
            "Readable and maintainable",
            "Complex and obfuscated",
            "Long and detailed",
            "Hidden from developers"
        ]
    },
    {
        "q": "What is 'Assertion Roulette'?",
        "o": [
            "Multiple assertions in a test without clear messages, making failure hard to trace",
            "Randomly passing tests",
            "A testing game",
            "Testing random numbers"
        ]
    },
    {
        "q": "How do you fix Assertion Roulette?",
        "o": [
            "Have one logical assertion per test or provide messages",
            "Remove assertions",
            "Write more tests",
            "Ignore failures"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "let a = null;\nexpect(a).toBeNull();",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "let a = undefined;\nexpect(a).toBeDefined();",
        "o": [
            "Fail",
            "Pass",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "Which of these is best practice for test data?",
        "o": [
            "Use meaningful but minimal data",
            "Use copy of production data",
            "Use random data always",
            "Use empty data"
        ]
    },
    {
        "q": "What is 'faking' in test doubles?",
        "o": [
            "Working implementation but not suitable for production (e.g., in-memory DB)",
            "Using real DB",
            "Returning null",
            "Throwing errors"
        ]
    },
    {
        "q": "What does 'TDD' encourage?",
        "o": [
            "Design improvements and confidence in code",
            "Writing code faster",
            "Skipping documentation",
            "Ignoring requirements"
        ]
    },
    {
        "q": "What is a 'Test Suite'?",
        "o": [
            "A collection of test cases",
            "A single test",
            "A testing tool",
            "A report"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "test('async', async () => {\n  const data = await Promise.resolve('data');\n  expect(data).toBe('data');\n});",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Timeout"
        ]
    },
    {
        "q": "Why use 'await' in async tests?",
        "o": [
            "To wait for the promise to resolve before asserting",
            "To make test faster",
            "To skip the test",
            "To run in parallel"
        ]
    },
    {
        "q": "What happens if you forget 'await' in an async test assertion?",
        "o": [
            "The test might finish before the assertion runs",
            "It works effectively",
            "It throws a syntax error",
            "It compiles fine"
        ]
    },
    {
        "q": "What is 'Behavior Verification'?",
        "o": [
            "Checking that certain methods were called",
            "Checking the return value",
            "Checking the state of object",
            "Checking the database"
        ]
    },
    {
        "q": "What is 'State Verification'?",
        "o": [
            "Checking the state/values of the object after action",
            "Checking which methods were called",
            "Checking logs",
            "Checking performance"
        ]
    },
    {
        "q": "What is the difference between specific exceptions and generic exceptions in testing?",
        "o": [
            "Specific exceptions ensure the correct error occurred",
            "Generic exceptions are easier to type",
            "Specific exceptions are deprecated",
            "There is no difference"
        ]
    },
    {
        "q": "When writing a test case, what should be testing first?",
        "o": [
            "The simplest success case",
            "The most complex error case",
            "The database connection",
            "The user login"
        ]
    },
    {
        "q": "What is 'Code Complexity'?",
        "o": [
            "A measure of how difficult code is to understand and test",
            "The length of the variable names",
            "The number of files in the project",
            "The cost of the software"
        ]
    },
    {
        "q": "High cyclomatic complexity usually indicates code is:",
        "o": [
            "Harder to test and maintain",
            "More efficient",
            "Better documented",
            "Easier to read"
        ]
    },
    {
        "q": "What is the 'Single Responsibility Principle' relation to testing?",
        "o": [
            "Classes with one responsibility are easier to test",
            "It makes testing harder",
            "It forces you to write fewer tests",
            "It requires multiple mocked objects"
        ]
    },
    {
        "q": "What is an 'assertion message'?",
        "o": [
            "A custom text displayed when an assertion fails",
            "A message sent to the developer on slack",
            "A comment in the code",
            "A variable name"
        ]
    },
    {
        "q": "Why include assertion messages?",
        "o": [
            "To quickly identify why a test failed",
            "To make the code look professional",
            "To increase file size",
            "To slowing down execution"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "let val = 100;\nexpect(val).toBeGreaterThan(50);",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "let val = 100;\nexpect(val).toBeLessThan(50);",
        "o": [
            "Fail",
            "Pass",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "Which pattern is used to initialize common objects for multiple tests?",
        "o": [
            "Test Fixture / Setup methods",
            "Copy Paste",
            "Global Variables",
            "Direct Instantiation everywhere"
        ]
    },
    {
        "q": "What is the risk of using shared global state in tests?",
        "o": [
            "Tests may interfere with each other (race conditions/pollution)",
            "It uses too much memory",
            "It is too fast",
            "It is deprecated"
        ]
    },
    {
        "q": "How do you handle random numbers in unit tests?",
        "o": [
            "Mock the random number generator or seed it",
            "Run the test multiple times until it passes",
            "Ignore the randomness",
            "Use fuzzy logic"
        ]
    },
    {
        "q": "How do you handle current time/date in unit tests?",
        "o": [
            "Mock the system clock (Time freezing)",
            "Wait for the correct time to run tests",
            "Change the system time manually",
            "Ignore time dependency"
        ]
    },
    {
        "q": "What is 'Test Pollution'?",
        "o": [
            "When side effects of one test affect another",
            "Writing too many tests",
            "Dirty code",
            "Using bad variable names"
        ]
    },
    {
        "q": "What is 'Test Isolation'?",
        "o": [
            "Ensuring each test runs in its own clean environment",
            "Running tests on a separate server",
            "Hiding tests from other developers",
            "Deleting tests"
        ]
    },
    {
        "q": "What is 'Dependency Injection' benefit for testing?",
        "o": [
            "Easier to replace dependencies with mocks",
            "Makes code shorter",
            "Removes need for classes",
            "Speeds up compilation"
        ]
    },
    {
        "q": "Which is an example of Dependency Injection?",
        "o": [
            "Passing a database service into a constructor",
            " creating 'new Database()' inside the method",
            "Using a global database variable",
            "Hardcoding connection string"
        ]
    },
    {
        "q": "What is 'Pair Programming' effect on testing?",
        "o": [
            "Often leads to higher quality tests and code review in real-time",
            "Reduces number of tests",
            "Slows down typing",
            "Increases bugs"
        ]
    },
    {
        "q": "What is 'Continuous Testing'?",
        "o": [
            "Running tests automatically as you code",
            "Testing only once a year",
            "Testing continuously for 24 hours",
            "Manual testing every day"
        ]
    },
    {
        "q": "What does 'expect.assertions(n)' do in Jest?",
        "o": [
            "Verifies that a certain number of assertions are called",
            "Limits the number of tests",
            "Sets the timeout",
            "Ignores assertions"
        ]
    },
    {
        "q": "When is 'expect.assertions(n)' useful?",
        "o": [
            "In async tests to ensure the callback/promise was actually executed",
            "In simple math tests",
            "When debugging strings",
            "To speed up tests"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "test('async', () => {\n  expect.assertions(1);\n  return Promise.resolve().then(() => {\n    expect(true).toBe(true);\n  });\n});",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Timeout"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "test('async fail', () => {\n  expect.assertions(1);\n  // No assertion here\n});",
        "o": [
            "Fail",
            "Pass",
            "Error",
            "Timeout"
        ]
    },
    {
        "q": "What is a 'Seam' in legacy code?",
        "o": [
            "A place where you can alter behavior without editing code (ideal for mocking)",
            "A bug in the code",
            "A comment line",
            "A syntax error"
        ]
    },
    {
        "q": "How improves testability of legacy code?",
        "o": [
            "Refactoring hard dependencies to be injectable",
            "Adding more comments",
            "Writing more documentation",
            "Deleting the code"
        ]
    },
    {
        "q": "What is 'In-Memory Database'?",
        "o": [
            "Database that runs in RAM, fast for testing",
            "Database on a USB stick",
            "Database in the cloud",
            "A text file"
        ]
    },
    {
        "q": "Why use In-Memory Database for unit tests?",
        "o": [
            "Speed and isolation (easily reset)",
            "Persistence",
            "Security",
            "Backup"
        ]
    },
    {
        "q": "What is 'Equivalence Partitioning'?",
        "o": [
            "Dividing input data into valid and invalid partitions",
            "Splitting code into files",
            "Partitioning the hard drive",
            "Sharing tests"
        ]
    },
    {
        "q": "What is 'Boundary Value Analysis'?",
        "o": [
            "Testing values at the edges of equivalence partitions",
            "Testing the UI boundaries",
            "Testing network limits",
            "Analyzing variable scope"
        ]
    },
    {
        "q": "If input accepts 1 to 100, what are boundary values?",
        "o": [
            "0, 1, 100, 101",
            "10, 50, 90",
            "-10, 200",
            "1, 2, 3"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "let arr = ['apple', 'banana'];\nexpect(arr).toContain('apple');",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "let arr = ['apple', 'banana'];\nexpect(arr).toContain('grape');",
        "o": [
            "Fail",
            "Pass",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'Branch Coverage'?",
        "o": [
            "Percentage of control flow branches (if/else) executed",
            "Number of git branches",
            "Number of office branches",
            "Number of boolean variables"
        ]
    },
    {
        "q": "Which is more detailed: Line Coverage or Branch Coverage?",
        "o": [
            "Branch Coverage",
            "Line Coverage",
            "They are the same",
            "Function Coverage"
        ]
    },
    {
        "q": "Why might 100% line coverage miss a bug?",
        "o": [
            "It may not test all logical combinations or empty branches",
            "It is too perfect",
            "It covers comments",
            "It ignores functions"
        ]
    },
    {
        "q": "What is 'Statement Coverage'?",
        "o": [
            "Percentage of executable statements run",
            "Percentage of functions called",
            "Percentage of classes used",
            "Percentage of files opened"
        ]
    },
    {
        "q": "What is 'Function Coverage'?",
        "o": [
            "Percentage of functions that have been called",
            "Number of function arguments",
            "Length of functions",
            "Return types"
        ]
    },
    {
        "q": "What is 'Path Coverage'?",
        "o": [
            "Testing all possible paths through the code",
            "Testing file paths",
            "Testing URL paths",
            "Testing API endpoints"
        ]
    },
    {
        "q": "Which coverage metric is hardest to achieve 100%?",
        "o": [
            "Path Coverage",
            "Function Coverage",
            "Statement Coverage",
            "Class Coverage"
        ]
    },
    {
        "q": "What is 'Test Data Builder' pattern?",
        "o": [
            "A pattern to easily create complex objects for tests",
            "A database tool",
            "A CI tool",
            "A compiler"
        ]
    },
    {
        "q": "Usage of 'beforeAll' vs 'beforeEach' affects:",
        "o": [
            "Test isolation and performance",
            "Syntax highlighting",
            "Compilation speed",
            "Code style"
        ]
    },
    {
        "q": "If 'beforeAll' sets up a shared DB connection, what is the risk?",
        "o": [
            "One test might corrupt the DB state for others",
            "It is slower",
            "It consumes more memory",
            "There is no risk"
        ]
    },
    {
        "q": "To prevent shared DB state issues, what should tests do?",
        "o": [
            "Use transactions and rollback after each test",
            "Delete the database",
            "Restart the server",
            "Run manually"
        ]
    },
    {
        "q": "What is 'Property-based Testing'?",
        "o": [
            "Verifying that code satisfies properties for a range of random inputs",
            "Testing class properties",
            "Testing CSS properties",
            "Testing specific values"
        ]
    },
    {
        "q": "Which library is famous for Property-based Testing in JS?",
        "o": [
            "fast-check",
            "redux",
            "express",
            "moment"
        ]
    },
    {
        "q": "What is a 'Test Spy' vs 'Mock'?",
        "o": [
            "Spy verifies side effects (calls); Mock verifies behavior/outputs strictly",
            "Spy is for spying",
            "Mock is for database",
            "They are the same"
        ]
    },
    {
        "q": "What is 'Characterization Testing'?",
        "o": [
            "Tests written to describe the behavior of existing (legacy) code",
            "Testing characters in strings",
            "Testing UI fonts",
            "Testing user roles"
        ]
    },
    {
        "q": "When is 'Characterization Testing' useful?",
        "o": [
            "Before refactoring legacy code to safety net existing behavior",
            "When starting a new project",
            "When designing UI",
            "When deploying"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const add = (a, b) => a + b;\nexpect(add(1, '2')).toBe('12');",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What issue does the previous test highlight?",
        "o": [
            "Type coercion leading to unexpected string concatenation",
            "Math error",
            "Syntax error",
            "Library failure"
        ]
    },
    {
        "q": "What is 'Visual Regression Testing'?",
        "o": [
            "Comparing pixel differences in UI screenshots",
            "Checking code style",
            "Checking code complexity",
            "Checking logs"
        ]
    },
    {
        "q": "Is Visual Regression Testing a Unit Test?",
        "o": [
            "Usually considered End-to-End or Integration, not Unit",
            "Yes, always",
            "No, it is manual",
            "It is a database test"
        ]
    },
    {
        "q": "What does 'toBeCloseTo' assert?",
        "o": [
            "Floating point equality within a precision",
            "String similarity",
            "Date proximity",
            "Array contents"
        ]
    },
    {
        "q": "Why use 'toBeCloseTo(0.3)' for '0.1 + 0.2'?",
        "o": [
            "Because floating point arithmetic can be imprecise (0.30000000000000004)",
            "It is faster",
            "It is shorter",
            "It is legacy"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "expect(0.1 + 0.2).toBe(0.3);",
        "o": [
            "Fail",
            "Pass",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'Fuzz Testing'?",
        "o": [
            "Inputting massive amounts of random data to find crashes",
            "Testing with fuzzy logic",
            "Testing hair styles",
            "Testing blurred images"
        ]
    },
    {
        "q": "What is a 'Test Runner'?",
        "o": [
            "Tool that executes tests and reports results (e.g., Karma, Jest CLI)",
            "Person who runs tests",
            "A fast computer",
            "A script file"
        ]
    },
    {
        "q": "What is methods 'skip' or 'xit' used for?",
        "o": [
            "To temporarily disable a test without deleting it",
            "To run a test first",
            "To run a test repeatedly",
            "To fail a test"
        ]
    },
    {
        "q": "What is methods 'only' or 'fit' used for?",
        "o": [
            "To run only the specified test(s) and ignore others",
            "To run test once",
            "To fix the test",
            "To delete other tests"
        ]
    },
    {
        "q": "What is 'Regression'?",
        "o": [
            "A bug that reappears after being fixed or a new bug in existing code",
            "Moving forward",
            "Writing code",
            "Deploying app"
        ]
    },
    {
        "q": "What is the 'Pyramid of Testing'?",
        "o": [
            "Strategy: Many unit tests, fewer integration tests, very few E2E tests",
            "All E2E tests",
            "No tests",
            "Equal number of all tests"
        ]
    },
    {
        "q": "Why is the base of the pyramid Unit Tests?",
        "o": [
            "They are fast, cheap, and pinpoint errors efficiently",
            "They are easy to write",
            "They are mandatory",
            "They look good"
        ]
    },
    {
        "q": "What is at the top of the testing pyramid?",
        "o": [
            "UI / End-to-End Tests",
            "Unit Tests",
            "Integration Tests",
            "Kernel Tests"
        ]
    },
    {
        "q": "What is a 'Brittle Test'?",
        "o": [
            "A test that breaks easily with harmless code changes (e.g., refactoring)",
            "A strong test",
            "A secure test",
            "A fast test"
        ]
    },
    {
        "q": "Which practice leads to brittle tests?",
        "o": [
            "Testing private methods or internal implementation details",
            "Testing public APIs",
            "Using dependency injection",
            "Following TDD"
        ]
    },
    {
        "q": "What does strict TDD forbid?",
        "o": [
            "Writing production code without a failing test first",
            "Writing comments",
            "Using IDEs",
            "Pair programming"
        ]
    },
    {
        "q": "What is 'Overspecified Test'?",
        "o": [
            "Test that checks too many details, making it fragile",
            "Test with no assertions",
            "Test with one assertion",
            "Test with comments"
        ]
    },
    {
        "q": "What is 'Contract Testing'?",
        "o": [
            "Verifying interactions between services based on an agreed contract",
            "Testing legal documents",
            "Testing with contractors",
            "Testing file sizes"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const fn = jest.fn();\nfn();\nexpect(fn).toHaveBeenCalled();",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const fn = jest.fn();\n// fn() not called\nexpect(fn).toHaveBeenCalled();",
        "o": [
            "Fail",
            "Pass",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'Deterministic' in testing?",
        "o": [
            "Given the same initial state and input, the test always produces the same output",
            "Random results",
            "Depends on time of day",
            "Depends on network"
        ]
    },
    {
        "q": "Non-deterministic tests are also called:",
        "o": [
            "Flaky tests",
            "Hard tests",
            "Good tests",
            "Unit tests"
        ]
    },
    {
        "q": "What does 'expect(obj).toHaveProperty(\"name\")' check?",
        "o": [
            "That the object has a key 'name'",
            "That the object is named 'name'",
            "That the object has value 'name'",
            "That the object is null"
        ]
    },
    {
        "q": "How can you test for an exception being thrown?",
        "o": [
            "Wrap the call in a function: expect(() => call()).toThrow()",
            "Call it directly: expect(call()).toThrow()",
            "Use try-catch block manually only",
            "It is impossible"
        ]
    },
    {
        "q": "Why wrap exception test in a function?",
        "o": [
            "To prevent the exception from crashing the test before assertion",
            "It is faster",
            "It is cleaner",
            "It is optional"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const boom = () => { throw new Error('Boom'); };\nexpect(() => boom()).toThrow('Boom');",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'Code Review' role in testing?",
        "o": [
            "Humans checking test quality and coverage logic",
            "Automated checking",
            "Compiling code",
            "Running tests"
        ]
    },
    {
        "q": "Can AI write unit tests?",
        "o": [
            "Yes, tools like Copilot can suggest tests",
            "No, never",
            "Only for Python",
            "Only for HTML"
        ]
    },
    {
        "q": "Do you need to test standard library functions (e.g., Math.max)?",
        "o": [
            "No, assume the language/library is already tested",
            "Yes, always",
            "Depends on the version",
            "Only if used in loops"
        ]
    },
    {
        "q": "Do you need to test getters and setters?",
        "o": [
            "Usually no, unless they contain logic",
            "Yes, always",
            "Never",
            "Only setters"
        ]
    },
    {
        "q": "What is 'Snapshot Update'?",
        "o": [
            "Process of approving the new output as the correct snapshot",
            "Deleting snapshots",
            "Ignoring failures",
            "Taking a new photo"
        ]
    },
    {
        "q": "What command usually updates snapshots in Jest?",
        "o": [
            "jest -u",
            "jest --fix",
            "jest --new",
            "jest --save"
        ]
    },
    {
        "q": "What is 'Coverage Report'?",
        "o": [
            "A generated document showing which lines were hit by tests",
            "A list of bugs",
            "A list of developers",
            "A performance chart"
        ]
    },
    {
        "q": "Which tool generates coverage reports in JS usually?",
        "o": [
            "Istanbul / nyc",
            "Webpack",
            "Babel",
            "ESLint"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "test.todo('implement login');",
        "o": [
            "Marks the test as 'skipped' or 'todo' in report",
            "Fail",
            "Pass",
            "Error"
        ]
    },
    {
        "q": "What is the main value of 'test.todo'?",
        "o": [
            "Reminds you to write a test later without breaking the build",
            "Does nothing",
            "Fails the build",
            "Deletes the test"
        ]
    },
    {
        "q": "What is 'Nondeterministic Polynomial time'?",
        "o": [
            "NP (Complexity class, typically not relevant to unit testing basics)",
            "New Protocol",
            "No Problem",
            "Network Port"
        ]
    },
    {
        "q": "In unit testing, what is 'SUT' isolation?",
        "o": [
            "Separating the System Under Test from its collaborators",
            "Isolating the developer",
            "Isolating the computer",
            "Isolating the network"
        ]
    },
    {
        "q": "What is the effect of 'flaky' tests on team confidence?",
        "o": [
            "It reduces confidence; developers start ignoring failures",
            "It increases confidence",
            "No effect",
            "It motivates them"
        ]
    },
    {
        "q": "How to handle a 3rd party API in unit tests?",
        "o": [
            "Mock the API calls",
            "Call the real API",
            "Ask the provider",
            "Skip testing"
        ]
    },
    {
        "q": "What is the 'Given-When-Then' style?",
        "o": [
            "A structure for BDD scenarios",
            "A looping construct",
            "A variable naming convention",
            "A git command"
        ]
    },
    {
        "q": "In 'Given-When-Then', what is 'Given'?",
        "o": [
            "The initial context/state",
            "The action",
            "The outcome",
            "The cleanup"
        ]
    },
    {
        "q": "In 'Given-When-Then', what is 'When'?",
        "o": [
            "The action or event",
            "The state",
            "The check",
            "The setup"
        ]
    },
    {
        "q": "In 'Given-When-Then', what is 'Then'?",
        "o": [
            "The expected outcome/assertion",
            "The action",
            "The setup",
            "The user"
        ]
    },
    {
        "q": "What is 'Table-Driven Testing'?",
        "o": [
            "Defining test cases in a table (inputs vs expected outputs) and iterating",
            "Testing database tables",
            "Testing HTML tables",
            "Testing on a table"
        ]
    },
    {
        "q": "What is the advantage of Table-Driven Testing?",
        "o": [
            "Reduces code duplication for similar test logic",
            "Makes tests slower",
            "Increases duplication",
            "Is only for Go language"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "expect(null).toBeNull();",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "expect(false).toBeFalsy();",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'Mock Object' in strict sense?",
        "o": [
            "Object that records method calls and asserts on them",
            "Object that returns null",
            "Object that crashes",
            "Object that speeds up tests"
        ]
    },
    {
        "q": "What is 'Stub' in strict sense?",
        "o": [
            "Object that provides canned answers to calls",
            "Object that records calls",
            "Object that asserts",
            "Object that validates"
        ]
    },
    {
        "q": "What is 'Fake' in strict sense?",
        "o": [
            "Working implementation (like in-memory DB) but simpler than production",
            "Broken implementation",
            "Slow implementation",
            "Real implementation"
        ]
    },
    {
        "q": "What is 'Spy' in strict sense?",
        "o": [
            "Wraps real object to record usage but calls through (usually)",
            "Replaces object completely",
            "Deletes object",
            "Hides object"
        ]
    },
    {
        "q": "What is 'Dummy' in strict sense?",
        "o": [
            "Passed around but never used (parameter filler)",
            "Used extensively",
            "Used for database",
            "Used for UI"
        ]
    },
    {
        "q": "What is the difference between Mock and Stub?",
        "o": [
            "Mocks test behavior (interaction), Stubs test state",
            "They are identical",
            "Mocks are slower",
            "Stubs are for API only"
        ]
    },
    {
        "q": "Which principle suggests 'Don't Mock Types You Don't Own'?",
        "o": [
            "London/Mockist School of TDD",
            "Chicago/Classic School",
            "Detroit School",
            "New York School"
        ]
    },
    {
        "q": "Why avoid mocking 3rd party libraries directly?",
        "o": [
            "Because library API might change; better to wrap in your own adapter",
            "Because it is impossible",
            "Because it is too fast",
            "Because it is illegal"
        ]
    },
    {
        "q": "What is 'Adapter Pattern' role in testing?",
        "o": [
            "Isolates application from external libraries, making mocking easier",
            "Connects to power outlet",
            "Speeds up runtime",
            "Reduces memory"
        ]
    },
    {
        "q": "What is 'Detroit School' of TDD also known as?",
        "o": [
            "Classic / Chicago School",
            "Mockist School",
            "London School",
            "Paris School"
        ]
    },
    {
        "q": "What does 'Classic School' focus on?",
        "o": [
            "State verification and real objects where possible",
            "Mocking everything",
            "Integration tests only",
            "No tests"
        ]
    },
    {
        "q": "What does 'London School' focus on?",
        "o": [
            "Behavior verification and extensive mocking",
            "Real objects",
            "State verification",
            "Database testing"
        ]
    },
    {
        "q": "Which school of thought promotes 'Outside-In' development?",
        "o": [
            "London School",
            "Chicago School",
            "Detroit School",
            "Embedded School"
        ]
    },
    {
        "q": "What is 'Testing Pyramid' middle layer?",
        "o": [
            "Integration / Service Tests",
            "Unit Tests",
            "UI Tests",
            "Manual Tests"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const spy = jest.spyOn(console, 'log');\nconsole.log('test');\nexpect(spy).toHaveBeenCalledWith('test');",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "Why is 'jest.restoreAllMocks()' important?",
        "o": [
            "Restores original implementations to avoid polluting other tests",
            "Deletes mocks",
            "Creates new mocks",
            "Runs all tests"
        ]
    },
    {
        "q": "What is 'Snapshot Diffing'?",
        "o": [
            "Saving only the difference between two snapshots",
            "Saving full snapshot every time",
            "Comparing two images visually",
            "Diffing two git branches"
        ]
    },
    {
        "q": "What is 'Invariant' in testing?",
        "o": [
            "A condition that should always be true for an object/system",
            "A variable that changes",
            "A constant that changes",
            "A failed test"
        ]
    },
    {
        "q": "How to test a private function in JS (modules)?",
        "o": [
            "Export it for testing (e.g., using 'export') or test via public function",
            "Change it to public permanently",
            "Copy paste code into test",
            "It cannot be tested"
        ]
    },
    {
        "q": "What implies that 'rewire' library is needed?",
        "o": [
            "To test non-exported private variables/functions in CommonJS",
            "To test wiring",
            "To test network",
            "To test CSS"
        ]
    },
    {
        "q": "What is 'Cyclomatic Complexity' threshold suggestion?",
        "o": [
            "Keep it low (e.g., under 10) to ensure testability",
            "High is better",
            "Zero is best",
            "100 is standard"
        ]
    },
    {
        "q": "What makes a function pure?",
        "o": [
            "Same input always gives same output + No side effects",
            "It calls database",
            "It uses random numbers",
            "It prints to console"
        ]
    },
    {
        "q": "Why are pure functions easier to test?",
        "o": [
            "No need for mocks or setup context",
            "They are smaller",
            "They are faster",
            "They use less memory"
        ]
    },
    {
        "q": "What is 'Strict Mock'?",
        "o": [
            "Tests fail if unexpected calls are made to it",
            "Allows any calls",
            "Ignores calls",
            "Logs calls"
        ]
    },
    {
        "q": "What is 'Loose Mock' / 'Nice Mock'?",
        "o": [
            "Allows unexpected calls (returns default/null) without failing",
            "Fails on any call",
            "Throws errors",
            "Deletes data"
        ]
    },
    {
        "q": "When is 'Loose Mock' appropriate?",
        "o": [
            "When the interaction is irrelevant to the specific test case",
            "Always",
            "Never",
            "For critical path"
        ]
    },
    {
        "q": "What is 'Test Harness'?",
        "o": [
            "Collection of software and test data to run program unit",
            "A physical harness",
            "A safety belt",
            "A debugger"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "test('timeout', (done) => {\n  setTimeout(() => { expect(1).toBe(1); done(); }, 1000);\n});",
        "o": [
            "Pass (after 1s)",
            "Fail immediately",
            "Error",
            "Timeout Error"
        ]
    },
    {
        "q": "What happens if 'done()' is never called in previous test?",
        "o": [
            "Test fails with Timeout Error",
            "Test passes implicitly",
            "Test runs forever",
            "Test is skipped"
        ]
    },
    {
        "q": "What is 'Property-Based Testing' shrinking?",
        "o": [
            "Finding the smallest/simplest input that causes failure",
            "Removing tests",
            "Compressing files",
            "Reducing font size"
        ]
    },
    {
        "q": "What is 'Monkey Patching' in tests?",
        "o": [
            "Dynamically modifying a module or class at runtime",
            "Testing monkeys",
            "Patching holes",
            "Updating OS"
        ]
    },
    {
        "q": "Why is Monkey Patching dangerous?",
        "o": [
            "Can affect other tests if not cleaned up (Global state pollution)",
            "It is too slow",
            "It is illegal",
            "It breaks build tools"
        ]
    },
    {
        "q": "What is 'Inline Snapshot'?",
        "o": [
            "Snapshot stored inside the test file itself",
            "Snapshot in a separate file",
            "Snapshot in database",
            "Snapshot in cloud"
        ]
    },
    {
        "q": "What is 'Parameterized Test' syntax in Jest?",
        "o": [
            "test.each(table)(name, fn)",
            "test.params(table)",
            "test.loop(table)",
            "test.iterate(table)"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "test.each([[1, 2, 3], [2, 2, 4]])('add(%i, %i)', (a, b, expected) => {\n  expect(a + b).toBe(expected);\n});",
        "o": [
            "Pass (runs 2 tests)",
            "Fail",
            "Error",
            "Skip"
        ]
    },
    {
        "q": "What is 'Code Coverage' branch vs path?",
        "o": [
            "Branch checks outcome of decisions; Path checks unique combinations of branches",
            "They are synonyms",
            "Path is simpler",
            "Branch is harder"
        ]
    },
    {
        "q": "What is 'MC/DC' coverage?",
        "o": [
            "Modified Condition/Decision Coverage",
            "Master Code Coverage",
            "Multi-Core Coverage",
            "Main Class Coverage"
        ]
    },
    {
        "q": "Where is MC/DC commonly used?",
        "o": [
            "Safety-critical systems (Avionics, Automotive)",
            "Web apps",
            "Game development",
            "Scripts"
        ]
    },
    {
        "q": "What is 'Test Double' generic term for?",
        "o": [
            "Mock, Stub, Spy, Fake, Dummy",
            "Only Mocks",
            "Only Spies",
            "Duplicate tests"
        ]
    },
    {
        "q": "What is 'Test Runner' vs 'Framework'?",
        "o": [
            "Runner executes tests (Karma); Framework provides structure/assertions (Jasmine)",
            "They are always same package",
            "Runner writes tests",
            "Framework runs tests"
        ]
    },
    {
        "q": "Jest acts as both:",
        "o": [
            "Test Runner and Assertion Framework",
            "Compiler and Editor",
            "Browser and server",
            "Database and Cache"
        ]
    },
    {
        "q": "What is 'Istanbul'?",
        "o": [
            "A JS code coverage tool",
            "A city in Turkey",
            "A testing framework",
            "A database"
        ]
    },
    {
        "q": "What is 'nyc'?",
        "o": [
            "Command line interface for Istanbul",
            "New York City",
            "New Year Countdown",
            "Node Yield Controller"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "expect(() => { throw new TypeError('oops'); }).toThrow(SyntaxError);",
        "o": [
            "Fail",
            "Pass",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "Why did previous test fail?",
        "o": [
            "Expected SyntaxError but got TypeError",
            "No error thrown",
            "Syntax error in test code",
            "Timeout"
        ]
    },
    {
        "q": "What is 'AssertionFree' testing?",
        "o": [
            "Tests that check if code runs without crashing (smoke tests)",
            "Tests with 0 assertions that always pass",
            "Bad practice",
            "Manual testing"
        ]
    },
    {
        "q": "What is 'Self-Validating' test?",
        "o": [
            "Test that reports its own result (Pass/Fail) without manual inspection",
            "Test that fixes itself",
            "Test that validates user input",
            "Test that writes itself"
        ]
    },
    {
        "q": "What is 'Test Discovery'?",
        "o": [
            "Process where test runner finds tests in the file system",
            "Discovering bugs",
            "Discovering new features",
            "Discovering documentation"
        ]
    },
    {
        "q": "What file extension pattern does Jest look for by default?",
        "o": [
            "__tests__ folders, .test.js, .spec.js",
            ".js files only",
            ".unit.js",
            ".code.js"
        ]
    },
    {
        "q": "What is 'Snapshot serializer'?",
        "o": [
            "Custom logic to format specific objects in snapshots",
            "A database serializer",
            "A JSON parser",
            "A XML writer"
        ]
    },
    {
        "q": "Why remove 'console.log' from tests?",
        "o": [
            "To keep test output clean and avoid noise",
            "It causes errors",
            "It is slow",
            "It is security risk"
        ]
    },
    {
        "q": "What is 'Mock function' .mock property?",
        "o": [
            "Contains calls, instances, contexts, and results",
            "Contains source code",
            "Contains comments",
            "Contains errors"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const mock = jest.fn();\nmock('arg1');\nconsole.log(mock.mock.calls[0][0]);",
        "o": [
            "arg1",
            "undefined",
            "mock",
            "Error"
        ]
    },
    {
        "q": "What is 'Green Bar'?",
        "o": [
            "Visual indicator that all tests passed",
            "A pub",
            "Money",
            "Progress bar"
        ]
    },
    {
        "q": "What is 'Red Bar'?",
        "o": [
            "Visual indicator that at least one test failed",
            "Stop sign",
            "Warning",
            "Error"
        ]
    },
    {
        "q": "What is 'Continuous Feedback'?",
        "o": [
            "Immediate results from tests during development",
            "Annual review",
            "User complaints",
            "Server logs"
        ]
    },
    {
        "q": "What implies 'Testable Architecture'?",
        "o": [
            "Loose coupling and high cohesion",
            "Spaghetti code",
            "Monolith",
            "Global variables"
        ]
    },
    {
        "q": "What is 'Circular Dependency' issue in testing?",
        "o": [
            "Hard to isolate modules involved in a cycle",
            "Makes tests faster",
            "Is good for coverage",
            "Is required for recursion"
        ]
    },
    {
        "q": "How to resolve Circular Dependency for testing?",
        "o": [
            "Refactor to extract common functionality or use Interface/Injection",
            "Ignore it",
            "Delete one module",
            "Merge files"
        ]
    },
    {
        "q": "What is 'Test First' approach?",
        "o": [
            "Writing tests before implementation (TDD)",
            "Writing tests after code",
            "Writing tests during code",
            "Writing ONLY tests"
        ]
    },
    {
        "q": "What is 'Test Last' approach?",
        "o": [
            "Writing tests after implementation (traditional)",
            "Writing tests before code",
            "Writing tests never",
            "Writing documentation"
        ]
    },
    {
        "q": "What is the disadvantage of Test Last?",
        "o": [
            "Code might be hard to test; tests might be biased to pass",
            "It takes less time",
            "It is more fun",
            "It uses less tools"
        ]
    },
    {
        "q": "What is 'Test Case Explosion'?",
        "o": [
            "Exponential increase in number of tests needed for combinations",
            "Tests blowing up",
            "Tests crashing",
            "Tests succeeding"
        ]
    },
    {
        "q": "How to mitigate Test Case Explosion?",
        "o": [
            "Pairwise testing or Orthogonal Arrays",
            "Write more tests",
            "Buy more servers",
            "Stop testing"
        ]
    },
    {
        "q": "What is 'Pairwise Testing'?",
        "o": [
            "Testing all possible pairs of parameter values",
            "Testing with a partner",
            "Testing two functions",
            "Testing double values"
        ]
    },
    {
        "q": "What is 'Test Orchestration'?",
        "o": [
            "Ordering and managing execution of test suites",
            "Writing tests music",
            "Conducting tests",
            "Automating UI"
        ]
    },
    {
        "q": "What is 'Soft Assertion'?",
        "o": [
            "Allows test to continue even if assertion fails (collects errors)",
            "Asserting softly",
            "Asserting maybe",
            "Asserting null"
        ]
    },
    {
        "q": "What is 'Hard Assertion'?",
        "o": [
            "Stops test execution immediately upon failure",
            "Asserting loudly",
            "Asserting definitely",
            "Asserting string"
        ]
    },
    {
        "q": "Most unit test frameworks default to:",
        "o": [
            "Hard Assertions",
            "Soft Assertions",
            "No Assertions",
            "Random Assertions"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "expect(undefined).toBeUndefined();",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "expect('abc').toMatch(/a/);",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "expect('abc').not.toMatch(/d/);",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'Integration' in 'CI' context?",
        "o": [
            "Merging code changes to main branch frequently",
            "Calculating area under curve",
            "Connecting to internet",
            "Installing plugins"
        ]
    },
    {
        "q": "What is 'Build Breaker'?",
        "o": [
            "Person or Commit that causes the CI pipeline to fail",
            "A heavy hammer",
            "A compilation tool",
            "A database error"
        ]
    },
    {
        "q": "What should you do if you break the build?",
        "o": [
            "Fix it immediately or revert the changes",
            "Go home",
            "Blame others",
            "Ignore emails"
        ]
    },
    {
        "q": "What is 'Pre-commit Hook'?",
        "o": [
            "Script running before commit (can run tests/lint)",
            "A fishing hook",
            "A git command",
            "A database trigger"
        ]
    },
    {
        "q": "Why use Pre-commit Hook for tests?",
        "o": [
            "To prevent bad code from entering repo",
            "To slow down development",
            "To annoy developers",
            "To increase repo size"
        ]
    },
    {
        "q": "What is 'Husky' often used for?",
        "o": [
            "Managing git hooks easily in node projects",
            "Sled dog",
            "Image compression",
            "CSS framework"
        ]
    },
    {
        "q": "WHAT IS 'TDD' PRIMARY GOAL?",
        "o": [
            "Design / Code Quality",
            "Test Coverage",
            "Finding Bugs",
            "Documentation"
        ]
    },
    {
        "q": "Does TDD guarantee good design?",
        "o": [
            "No, but it encourages it",
            "Yes, absolutely",
            "No, it ruins design",
            "Yes, if used with Java"
        ]
    },
    {
        "q": "What is 'Refactoring' trigger in TDD?",
        "o": [
            "Green state (Tests passing)",
            "Red state (Tests failing)",
            "Blue state",
            "Before writing tests"
        ]
    },
    {
        "q": "Why refactor only on Green?",
        "o": [
            "To ensure you don't break existing functionality while changing structure",
            "To make it harder",
            "To save time",
            "Because red is dangerous"
        ]
    },
    {
        "q": "What is 'Legacy Code' definition by Michael Feathers?",
        "o": [
            "Code without tests",
            "Old code",
            "COBOL code",
            "Bad code"
        ]
    },
    {
        "q": "What is the first step working with Legacy Code?",
        "o": [
            "Write characterization tests",
            "Rewrite it",
            "Delete it",
            "Format it"
        ]
    },
    {
        "q": "What is 'Sprout Method'?",
        "o": [
            "New functionality is added as a new method and called/tested",
            "A gardening technique",
            "A git branch",
            "A class extension"
        ]
    },
    {
        "q": "What is 'Wrap Method'?",
        "o": [
            "Old method is renamed; new method calls old one + new logic",
            "Wrapping text",
            "Packaging code",
            "Hiding method"
        ]
    },
    {
        "q": "What is 'Behavioral Testing' vs 'Structural Testing'?",
        "o": [
            "Testing what the system does (black-box) vs how it is built (white-box)",
            "Testing behavior of users vs structure of database",
            "Testing CSS vs HTML",
            "Testing animations vs layouts"
        ]
    },
    {
        "q": "What is 'Orthogonal Array Testing'?",
        "o": [
            "Statistical technique to select a subset of test cases that cover all pair combinations",
            "Testing arrays",
            "Testing geometry",
            "Testing orthogonal lines"
        ]
    },
    {
        "q": "What is 'All-Pairs Testing'?",
        "o": [
            "Same as pairwise testing; testing all pairs of variables",
            "Testing all items",
            "Testing all files",
            "Testing pairs of developers"
        ]
    },
    {
        "q": "What is 'State-Transition Testing'?",
        "o": [
            "Testing if valid state transitions occur and invalid ones are blocked",
            "Testing CSS transitions",
            "Testing state of USA",
            "Testing navigation"
        ]
    },
    {
        "q": "When to use State-Transition Testing?",
        "o": [
            "When the system has a finite number of states (e.g., order processing flow)",
            "For stateless functions",
            "For styling",
            "For static pages"
        ]
    },
    {
        "q": "What is 'Decision Table Testing'?",
        "o": [
            "Using a table to map multiple input conditions to actions",
            "Deciding where to sit",
            "Testing tables",
            "Testing databases"
        ]
    },
    {
        "q": "What is 'Use Case Testing'?",
        "o": [
            "Designing tests based on user scenarios or use cases",
            "Testing useful cases",
            "Testing useless cases",
            "Testing syntax"
        ]
    },
    {
        "q": "What is 'Statement Coverage' formula?",
        "o": [
            "(Number of executed statements / Total statements) * 100",
            "(Total statements / Executed statements) * 100",
            "Statements + Tests",
            "Statements - Tests"
        ]
    },
    {
        "q": "What is 'Branch Coverage' formula?",
        "o": [
            "(Number of executed branches / Total branches) * 100",
            "Branches * 100",
            "Branches / Files",
            "Branches + Loops"
        ]
    },
    {
        "q": "What is 'Cyclomatic Complexity' formula (simplified)?",
        "o": [
            "Edges - Nodes + 2 * ConnectedComponents (or simply Branches + 1)",
            "Lines of code / 10",
            "Files * 2",
            "Classes + Methods"
        ]
    },
    {
        "q": "What allows 'jest.mock' to hoist modules?",
        "o": [
            "Babel plugin that moves mocks to the top of the file automatically",
            "Magic",
            "The OS",
            "Node.js"
        ]
    },
    {
        "q": "What is 'Manual Mock' in Jest?",
        "o": [
            "Creating a __mocks__ folder with module implementation",
            "Typing mock manually every time",
            "A mock made of wood",
            "A paper mock"
        ]
    },
    {
        "q": "What does 'jest.genMockFromModule()' do?",
        "o": [
            "Automatically generates a mock based on the module's export structure",
            "Downloads a mock from npm",
            "Deletes the module",
            "Compiles the module"
        ]
    },
    {
        "q": "What is 'Regression Test Selection'?",
        "o": [
            "Choosing only relevant tests to run based on changes",
            "Selecting all tests",
            "Selecting random tests",
            "Selecting hard tests"
        ]
    },
    {
        "q": "What is 'Test Impact Analysis'?",
        "o": [
            "Analyzing which tests are affected by code changes",
            "Hitting the computer",
            "Analyzing crash reports",
            "Analyzing user analytics"
        ]
    },
    {
        "q": "What is 'Shift Left' testing?",
        "o": [
            "Moving testing earlier in the development lifecycle",
            "Moving text left",
            "Testing on left monitor",
            "Testing leftist politics"
        ]
    },
    {
        "q": "What is 'Shift Right' testing?",
        "o": [
            "Testing in production (monitoring, feature flags, canary)",
            "Moving text right",
            "Testing right monitor",
            "Testing rightist politics"
        ]
    },
    {
        "q": "What is 'Canary Release'?",
        "o": [
            "Rolling out update to a small subset of users first",
            "Releasing a bird",
            "Releasing yellow app",
            "Releasing fast"
        ]
    },
    {
        "q": "What is 'Blue-Green Deployment' relation to testing?",
        "o": [
            "Allows testing on the idle environment before switching traffic",
            "Testing colors",
            "Testing nature",
            "Testing displays"
        ]
    },
    {
        "q": "What is 'A/B Testing'?",
        "o": [
            "Comparing two versions to see which performs better (UX/Business)",
            "Testing alphabet",
            "Unit testing A and B",
            "Testing blood type"
        ]
    },
    {
        "q": "Is A/B Testing part of Unit Testing?",
        "o": [
            "No, it is a business/UX experiment technique",
            "Yes",
            "Sometimes",
            "Only in Python"
        ]
    },
    {
        "q": "What is 'Chaos Engineering'?",
        "o": [
            "Intentionally introducing faults to test resilience (e.g., Chaos Monkey)",
            "Bad engineering",
            "Random coding",
            "Testing physics"
        ]
    },
    {
        "q": "What is 'Property-based Testing' advantage over Example-based?",
        "o": [
            "Finds edge cases you didn't think of by generating inputs",
            "It is faster",
            "It is easier",
            "It requires no code"
        ]
    },
    {
        "q": "What is 'Example-based Testing'?",
        "o": [
            "Traditional unit testing with specific input/output examples",
            "Testing only examples",
            "Copying examples",
            "Testing documentation"
        ]
    },
    {
        "q": "What is 'Metamorphic Testing'?",
        "o": [
            "Checking relations between outputs of multiple inputs (e.g., sin(x) = sin(180-x))",
            "Testing butterflies",
            "Testing shapes",
            "Testing transformers"
        ]
    },
    {
        "q": "When is Metamorphic Testing used?",
        "o": [
            "When the exact 'oracle' (expected output) is hard to determine",
            "Always",
            "Never",
            "For simple math"
        ]
    },
    {
        "q": "What is a 'Test Oracle'?",
        "o": [
            "The mechanism for determining whether a test has passed or failed",
            "A database",
            "A fortune teller",
            "A company"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const p = Promise.reject('fail');\nexpect(p).rejects.toMatch('fail');",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const p = Promise.resolve('ok');\nexpect(p).resolves.toBe('ok');",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'Test Driven Infrastructure'?",
        "o": [
            "Writing tests for infrastructure code (e.g., Terraform/Ansible) before deploying",
            "Building buildings",
            "Driving cars",
            "Testing roads"
        ]
    },
    {
        "q": "What is 'Linting' vs 'Testing'?",
        "o": [
            "Linting checks syntax/style; Testing checks behavior/logic",
            "They are same",
            "Linting is testing",
            "Testing is linting"
        ]
    },
    {
        "q": "What is 'Static Analysis'?",
        "o": [
            "Analyzing code without executing it (e.g., ESLint, TypeScript)",
            "Analyzing electricity",
            "Analyzing frozen code",
            "Analyzing data"
        ]
    },
    {
        "q": "What is 'Dynamic Analysis'?",
        "o": [
            "Analyzing code while it is running (e.g., Profiling, Coverage)",
            "Analyzing moving code",
            "Analyzing websites",
            "Analyzing videos"
        ]
    },
    {
        "q": "What is 'Code Complexity' metric 'Halstead Complexity'?",
        "o": [
            "Measures vocabulary, length, difficulty, and effort",
            "Measures lines of code",
            "Measures file size",
            "Measures time"
        ]
    },
    {
        "q": "What implies low 'Testability'?",
        "o": [
            "Tightly coupled code, hidden dependencies, non-determinism",
            "Interfaces",
            "Dependency Injection",
            "Pure functions"
        ]
    },
    {
        "q": "How to improve testability of a Singleton?",
        "o": [
            "Allow resetting the instance or dependency injection",
            "Make it global",
            "Delete it",
            "Make it private"
        ]
    },
    {
        "q": "Why imply Singleton is bad for testing?",
        "o": [
            "Carries state across tests (Order dependency)",
            "It is too simple",
            "It is too fast",
            "It is used in Java"
        ]
    },
    {
        "q": "What is 'Global State' problem?",
        "o": [
            "Changes in one test persist and break subsequent tests",
            "Global warming",
            "World politics",
            "Large files"
        ]
    },
    {
        "q": "What is 'Database Seeding'?",
        "o": [
            "Populating database with initial data for testing",
            "Planting trees",
            "Deleting data",
            "Backing up data"
        ]
    },
    {
        "q": "What is 'Database Migration' testing?",
        "o": [
            "Verifying that schema changes apply correctly without data loss",
            "Moving birds",
            "Moving servers",
            "Copying files"
        ]
    },
    {
        "q": "What is 'Test Smell' - 'Mystery Guest'?",
        "o": [
            "Test uses external resources/data not explicitly seen in the test code",
            "Unknown user",
            "Hidden file",
            "Encrypted data"
        ]
    },
    {
        "q": "What is 'Test Smell' - 'General Fixture'?",
        "o": [
            "Setup is too large and general, making it hard to see what is needed for specific test",
            "A light fixture",
            "A broken test",
            "A global variable"
        ]
    },
    {
        "q": "What is 'Test Smell' - 'Eager Test'?",
        "o": [
            "Test checks too many different methods/functionalities",
            "Test runs fast",
            "Test runs early",
            "Test passes"
        ]
    },
    {
        "q": "What is 'Test Smell' - 'Lazy Test'?",
        "o": [
            "Test checks multiple things but with one weak assertion or none",
            "Test runs slow",
            "Test runs later",
            "Test fails"
        ]
    },
    {
        "q": "What is 'Parameterized Test' main benefit?",
        "o": [
            "Avoids duplicating the same test structure for different data",
            "Runs faster",
            "Uses less memory",
            "Looks cooler"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const mock = jest.fn().mockReturnValue(42);\nexpect(mock()).toBe(42);",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const mock = jest.fn().mockImplementation(x => x + 1);\nexpect(mock(1)).toBe(2);",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'Snapshot Testing' best used for?",
        "o": [
            "React components, configuration objects, extensive JSON responses",
            "Math formulas",
            "Loop logic",
            "Database connections"
        ]
    },
    {
        "q": "What is the danger of Snapshot Testing?",
        "o": [
            "Developers might just update snapshots without verifying changes (Treating as 'accept all')",
            "It takes too much disk space",
            "It is slow",
            "It requires a camera"
        ]
    },
    {
        "q": "What is 'Visual Regression Tools' examples?",
        "o": [
            "Percy, Applitools, BackstopJS",
            "Photoshop",
            "Paint",
            "Figma"
        ]
    },
    {
        "q": "What is 'Heuristic' in testing?",
        "o": [
            "Rule of thumb or strategy to guide testing (e.g., test boundaries)",
            "A virus",
            "A bug",
            "A tool"
        ]
    },
    {
        "q": "What is 'Session-Based Testing'?",
        "o": [
            "Time-boxed exploratory testing sessions with specific charters",
            "Testing login sessions",
            "Testing cookies",
            "Testing meetings"
        ]
    },
    {
        "q": "What is 'Test Charter'?",
        "o": [
            "A mission statement for a session of exploratory testing",
            "A map",
            "A contract",
            "A certificate"
        ]
    },
    {
        "q": "What is 'Ad-hoc Testing'?",
        "o": [
            "Testing without a plan or documentation (random)",
            "Planned testing",
            "Automated testing",
            "Unit testing"
        ]
    },
    {
        "q": "What is 'Sanity Testing'?",
        "o": [
            "Subset of regression testing to verify a specific fix works (narrow regression)",
            "Checking mental health",
            "Deep regression",
            "Performance test"
        ]
    },
    {
        "q": "Difference between Smoke and Sanity testing?",
        "o": [
            "Smoke verifies critical path (broad/shallow); Sanity verifies specific functionality (narrow/deep)",
            "They are same",
            "Smoke is deep, Sanity is shallow",
            "Smoke is manual, Sanity is auto"
        ]
    },
    {
        "q": "What is 'Race Condition'?",
        "o": [
            "System behavior depends on sequence/timing of uncontrollable events",
            "A car race",
            "A marathon",
            "A fast code"
        ]
    },
    {
        "q": "How to test Race Conditions?",
        "o": [
            "Run tests in parallel loops, use delays, or specific tools (concurrency testing)",
            "Run faster",
            "Run slower",
            "Cannot be tested"
        ]
    },
    {
        "q": "What is 'Deadlock'?",
        "o": [
            "Access to resources is blocked because two processes are waiting for each other",
            "A locked door",
            "A crash",
            "A slow network"
        ]
    },
    {
        "q": "What is 'Livelock'?",
        "o": [
            "Processes keep changing state in response to each other without progress",
            "A live video",
            "A running process",
            "A fast lock"
        ]
    },
    {
        "q": "What is 'Mocking Framework' example in Java?",
        "o": [
            "Mockito",
            "JUnit",
            "Selenium",
            "Maven"
        ]
    },
    {
        "q": "What is 'Mocking Framework' example in Python?",
        "o": [
            "unittest.mock",
            "pytest",
            "Django",
            "Flask"
        ]
    },
    {
        "q": "What is 'Mocking Framework' example in C#?",
        "o": [
            "Moq",
            "NUnit",
            "xUnit",
            "dotnet"
        ]
    },
    {
        "q": "What is 'PowerMock' used for?",
        "o": [
            "Mocking static methods, constructors, final classes (legacy java)",
            "Power management",
            "Mocking power usage",
            "Battery testing"
        ]
    },
    {
        "q": "What is 'Test Container'?",
        "o": [
            "Using Docker containers to spin up dependencies (DB, Redis) for integration tests",
            "A box for tests",
            "A folder",
            "A zip file"
        ]
    },
    {
        "q": "What is 'TestContainers' library?",
        "o": [
            "Java/Node/Go library to manage Docker containers for testing",
            "Library for UI",
            "Library for CSS",
            "Library for sound"
        ]
    },
    {
        "q": "What is 'Service Virtualization'?",
        "o": [
            "Simulating behavior of dependent components (APIs) that are unavailable",
            "Virtual Reality",
            "Cloud computing",
            "Docker"
        ]
    },
    {
        "q": "Difference between Mocking and Service Virtualization?",
        "o": [
            "Mocking is typically in-process (unit); SV is over the network (integration/system)",
            "They are same",
            "Mocking is network",
            "SV is in-process"
        ]
    },
    {
        "q": "What is 'Test Pyramid' anti-pattern 'Ice Cream Cone'?",
        "o": [
            "Many UI/Manual tests, few Unit tests (inverted pyramid)",
            "Eating ice cream",
            "Many unit tests",
            "Perfect pyramid"
        ]
    },
    {
        "q": "Why is 'Ice Cream Cone' bad?",
        "o": [
            "Tests are slow, brittle, and expensive to maintain",
            "It melts",
            "It is tasty",
            "It is fast"
        ]
    },
    {
        "q": "What is 'Test Pyramid' anti-pattern 'Hourglass'?",
        "o": [
            "Many Unit and UI tests, but few Integration tests",
            "Use sand",
            "Measure time",
            "Symmetric tests"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const fn = jest.fn();\nfn('a');\nfn('b');\nexpect(fn).toHaveBeenCalledTimes(2);",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "const fn = jest.fn();\nfn('a');\nexpect(fn).toHaveBeenLastCalledWith('a');",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'Coverage Gaps'?",
        "o": [
            "Areas of code not executed by any test",
            "Missing clothes",
            "Blank lines",
            "Comments"
        ]
    },
    {
        "q": "How to identify coverage gaps?",
        "o": [
            "Use coverage report visualization (HTML report red lines)",
            "Read code",
            "Guess",
            "Ask AI"
        ]
    },
    {
        "q": "What is 'Branch Predicate'?",
        "o": [
            "The boolean condition determining the branch (e.g., x > 5)",
            "The tree branch",
            "The git branch naming",
            "The loop variable"
        ]
    },
    {
        "q": "What does 'expect.objectContaining' do?",
        "o": [
            "Checks if object contains subset of properties",
            "Checks strict equality",
            "Checks if object is empty",
            "Checks if object is null"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "expect({a: 1, b: 2}).toEqual(expect.objectContaining({a: 1}));",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'Snapshots' drawbacks?",
        "o": [
            "Easy to commit wrong snapshots; failures might be noise; coupled to implementation details",
            "None",
            "Slow",
            "Hard to use"
        ]
    },
    {
        "q": "How to reduce Snapshot flakiness?",
        "o": [
            "Use property matchers for dynamic fields (IDs, dates)",
            "Delete snapshots",
            "Stop testing",
            "Use PNGs"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "expect({ id: Date.now() }).toMatchSnapshot({ id: expect.any(Number) });",
        "o": [
            "Pass (ignores exact ID value)",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What implies 'Test Maintenance' cost?",
        "o": [
            "Time spent fixing tests when code changes",
            "Cost of server",
            "Cost of tools",
            "Salary"
        ]
    },
    {
        "q": "Best way to reduce Test Maintenance?",
        "o": [
            "Write implementation-agnostic tests; focus on behavior",
            "Delete tests",
            "Write no tests",
            "Hire more testers"
        ]
    },
    {
        "q": "What is 'Zombie Code'?",
        "o": [
            "Code that is never executed (Dead code)",
            "Code that eats brains",
            "Scary code",
            "Slow code"
        ]
    },
    {
        "q": "Does coverage report find Zombie Code?",
        "o": [
            "Yes, it shows up as uncovered (red)",
            "No",
            "Maybe",
            "Only if commented"
        ]
    },
    {
        "q": "What is 'N-Version Programming'?",
        "o": [
            "Developing multiple versions of same software independently to reduce common errors (Reliability)",
            "Versioning git",
            "Backups",
            "CI/CD"
        ]
    },
    {
        "q": "What is 'Back-to-Back Testing'?",
        "o": [
            "Comparing outputs of N versions of software for same inputs",
            "Testing back muscles",
            "Testing reverse",
            "Testing backend"
        ]
    },
    {
        "q": "What is 'Test Flakiness' root cause related to Async?",
        "o": [
            "Race conditions between test execution and async callback/promise resolution",
            "Network speed",
            "CPU speed",
            "RAM size"
        ]
    },
    {
        "q": "What is 'Resource Leak' in testing?",
        "o": [
            "Tests failing to clean up resources (DB connections, open handles) causes subsequent tests to fail or hang",
            "Leaking water",
            "Memory leak only",
            "Disk leak"
        ]
    },
    {
        "q": "How to detect Open Handles in Jest?",
        "o": [
            "Run with --detectOpenHandles flag",
            "Run with --leaks",
            "Run with --debug",
            "Run with --verbose"
        ]
    },
    {
        "q": "What is 'Test Doubles' - 'Spies' behavior on existing methods?",
        "o": [
            "They wrap the method, allowing call tracking, and can optionally delegate to original implementation",
            "They always delete original method",
            "They act as virus",
            "They are illegal"
        ]
    },
    {
        "q": "What is 'Deterministic Execution'?",
        "o": [
            "The property that a system/test always behaves exactly the same way given same inputs",
            "Random execution",
            "Fast execution",
            "Slow execution"
        ]
    },
    {
        "q": "What disrupts Deterministic Execution in tests?",
        "o": [
            "Uncontrolled concurrency, time dependency, random seeds, external services",
            "Naming variables",
            "Comments",
            "Long functions"
        ]
    },
    {
        "q": "What is 'Hiawatha' approach to legacy code?",
        "o": [
            "Not a standard term (Trick question / mythical)",
            "A famous pattern",
            "A tool",
            "A language"
        ]
    },
    {
        "q": "What is 'Mikado Method'?",
        "o": [
            "A structured process for significant refactoring (explore, backing out, making small changes)",
            "A game",
            "A sushi",
            "A test runner"
        ]
    },
    {
        "q": "What is 'Golden Master' testing?",
        "o": [
            "Capturing output of a legacy system and using it as a baseline (Snapshot) for refactoring",
            "A golden trophy",
            "A gold mine",
            "A master key"
        ]
    },
    {
        "q": "When is Golden Master testing risky?",
        "o": [
            "When the output contains non-deterministic data (dates, IDs) that changes every run",
            "When system is small",
            "When system is fast",
            "When system is new"
        ]
    },
    {
        "q": "What is 'Pesticide Paradox'?",
        "o": [
            "If you repeat the same tests, they eventually stop finding new bugs (Paradox of repetitive testing)",
            "Bugs become stronger",
            "Tests kill bugs",
            "Using pesticides on computers"
        ]
    },
    {
        "q": "How to overcome Pesticide Paradox?",
        "o": [
            "Regularly review and update/add new test cases",
            "Stop testing",
            "Use stronger tools",
            "Delete old code"
        ]
    },
    {
        "q": "What is 'Error Guessing'?",
        "o": [
            "Test design technique where testers use intuition/experience to guess where bugs lie",
            "Random guessing",
            "Calculated guessing",
            "Machine guessing"
        ]
    },
    {
        "q": "What is 'State Space Explosion'?",
        "o": [
            "When the number of possible states in a system grows exponentially, making exhaustive testing impossible",
            "Exploding computer",
            "Space travel",
            "Large hard drive"
        ]
    },
    {
        "q": "What is 'Model Checking'?",
        "o": [
            "Algorithmic verification of a system against a specification (finite state model)",
            "Checking fashion models",
            "Checking database models",
            "Checking 3D models"
        ]
    },
    {
        "q": "What is 'Symbolic Execution'?",
        "o": [
            "Analyzing program to determine what inputs cause each part of a program to execute (using symbols instead of values)",
            "Executing symbols",
            "Running icons",
            "Manual testing"
        ]
    },
    {
        "q": "What is 'Concolic Testing'?",
        "o": [
            "Hybrid of Concrete and Symbolic execution",
            "Concrete testing",
            "Symbolic testing",
            "Manual testing"
        ]
    },
    {
        "q": "What is 'Test Suite Minimization'?",
        "o": [
            "Removing redundant tests that do not add coverage or value",
            "Making tests small text",
            "Hiding tests",
            "Archiving tests"
        ]
    },
    {
        "q": "What is 'Test Case Prioritization'?",
        "o": [
            "Ordering tests to maximize fault detection rate (fail fast)",
            "Ordering alphabetically",
            "Ordering by size",
            "Ordering by author"
        ]
    },
    {
        "q": "What is 'Combinatorial Testing'?",
        "o": [
            "Testing combinations of input parameters (Pairwise, N-wise)",
            "Combining files",
            "Combining definitions",
            "Mixing colors"
        ]
    },
    {
        "q": "What is 'Bogus Test'?",
        "o": [
            "Test that passes significantly but tests nothing real (e.g. assert(true))",
            "A scary test",
            "A swamp test",
            "A bonus test"
        ]
    },
    {
        "q": "What is 'Test Hook' (in code)?",
        "o": [
            "Code added purely to enable testing (e.g., exposing private state via getter)",
            "A fishing hook",
            "A pirate hook",
            "A git hook"
        ]
    },
    {
        "q": "Is adding Test Hooks good practice?",
        "o": [
            "Ideally avoid; if necessary, make them package-private or visible only for testing",
            "Yes, always good",
            "No, never",
            "Only in C++"
        ]
    },
    {
        "q": "What is 'Coverage Inflation'?",
        "o": [
            "High coverage numbers but low assertion quality (executing code without verifying it)",
            "Prices going up",
            "More files",
            "Larger binary"
        ]
    },
    {
        "q": "What is 'Pseudo-tested' code?",
        "o": [
            "Code that is executed by tests but no assertions actually check its behavior",
            "Fake code",
            "Partial code",
            "Beta code"
        ]
    },
    {
        "q": "What is 'Mutation Score'?",
        "o": [
            "Percentage of mutants (injected faults) killed by the test suite",
            "Score in a game",
            "Genetic score",
            "Code quality score"
        ]
    },
    {
        "q": "What is a 'Survivor' in mutation testing?",
        "o": [
            "A mutant that survived the tests (test presumably inadequate)",
            "Winner",
            "Loser",
            "A bug"
        ]
    },
    {
        "q": "What is 'Equivalent Mutant'?",
        "o": [
            "A mutant that behaves exactly like the original code (cannot be killed)",
            "A clone",
            "A bug",
            "A feature"
        ]
    },
    {
        "q": "What is 'Trivial Mutant'?",
        "o": [
            "A mutant that is easily killed by almost any test",
            "A small bug",
            "A big bug",
            "A comment"
        ]
    },
    {
        "q": "What is 'Higher Order Mutation'?",
        "o": [
            "Applying multiple mutations simultaneously to find complex interactions",
            "Advanced biology",
            "Complex math",
            "String theory"
        ]
    },
    {
        "q": "What is 'Fuzzing' generation-based vs mutation-based?",
        "o": [
            "Gen-based creates inputs from scratch; Mutation-based modifies valid inputs",
            "They are same",
            "Gen-based is slow",
            "Mutation-based is fast"
        ]
    },
    {
        "q": "What is 'Smart Fuzzing'?",
        "o": [
            "Fuzzing tailored with knowledge of file format or protocol",
            "AI fuzzing",
            "Manual fuzzing",
            "Random fuzzing"
        ]
    },
    {
        "q": "What is 'Property-based Testing' - 'Shrinking' process?",
        "o": [
            "Simplifying a failing case to the minimal example (e.g. long string -> short string)",
            "Deleting files",
            "Reducing memory",
            "Compressing text"
        ]
    },
    {
        "q": "What is 'Slicing' in debugging/testing?",
        "o": [
            "Isolating statements that could affect value of variable at a point",
            "Cutting bread",
            "Splitting files",
            "Deleting code"
        ]
    },
    {
        "q": "What is 'Test Refactoring'?",
        "o": [
            "Improving structure/readability of test code without changing its verification logic",
            "Changing what test checks",
            "Deleting tests",
            "Adding features"
        ]
    },
    {
        "q": "Refactoring production code vs Test code?",
        "o": [
            "Refactor production code when tests pass; Refactor tests when they are brittle/messy",
            "Never refactor tests",
            "Refactor both randomly",
            "Refactor only on Tuesdays"
        ]
    },
    {
        "q": "What is 'Test Smell' - 'Incidental Details'?",
        "o": [
            "Test contains too much setup data irrelevant to the assertion",
            "Accidents",
            "Incidents",
            "Logs"
        ]
    },
    {
        "q": "What is 'Test Smell' - 'Split Logic'?",
        "o": [
            "Test logic is split across files making it hard to read",
            "Logic gates",
            "Split screen",
            "Split personality"
        ]
    },
    {
        "q": "What is 'Test Smell' - 'Conditional Test Logic'?",
        "o": [
            "Using if/loops in tests (makes test complex and prone to bugs)",
            "Testing conditions",
            "Conditional rendering",
            "Conditional formatting"
        ]
    },
    {
        "q": "Why avoid conditionals (if/else) in tests?",
        "o": [
            "The test should check a specific path; conditionals suggest multiple paths (better split into two tests)",
            "They are slow",
            "They are ugly",
            "They are deprecated"
        ]
    },
    {
        "q": "What is 'Test Smell' - 'Erratic Test'?",
        "o": [
            "Flaky test (sometimes passes, sometimes fails)",
            "Crazy test",
            "Fast test",
            "Slow test"
        ]
    },
    {
        "q": "What is root cause of 'Interacting Tests'?",
        "o": [
            "Shared state (static variables, DB, files) not cleaned up",
            "Tests talking to each other",
            "Social tests",
            "AI tests"
        ]
    },
    {
        "q": "What is 'Teardown' importance?",
        "o": [
            "Ensuring environment is reset so next test runs clean",
            "Making developers cry",
            "Breaking code",
            "Deleting app"
        ]
    },
    {
        "q": "What is 'Fresh Fixture' strategy?",
        "o": [
            "Creating a fresh test fixture/environment for every test case",
            "Buying new hardware",
            "Cleaning screen",
            "Using new code"
        ]
    },
    {
        "q": "What is 'Shared Fixture' strategy?",
        "o": [
            "Reusing the same fixture for multiple tests (faster but risky)",
            "Sharing computer",
            "Sharing passwords",
            "Sharing lunch"
        ]
    },
    {
        "q": "When to favor Shared Fixture?",
        "o": [
            "When setup is extremely expensive (e.g. DB creation) and tests are read-only",
            "Always",
            "Never",
            "When lazy"
        ]
    },
    {
        "q": "What is 'Automated Teardown'?",
        "o": [
            "Framework automatically handles cleanup (e.g. rolling back transaction)",
            "Robots cleaning",
            "Auto delete",
            "Auto format"
        ]
    },
    {
        "q": "What is 'Test Data Management'?",
        "o": [
            "Strategy for creation, maintenance, and teardown of test data",
            "Managing files",
            "Managing database",
            "Managing memory"
        ]
    },
    {
        "q": "What is 'Test Independent'?",
        "o": [
            "Tests can run in any order",
            "Tests run alone",
            "Tests depend on internet",
            "Tests depend on user"
        ]
    },
    {
        "q": "What is 'Data Sensitivity' in testing?",
        "o": [
            "Avoiding PII/sensitive data in tests/logs",
            "Testing feelings",
            "Touch screen testing",
            "Sensor testing"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "jest.useFakeTimers();\nsetTimeout(cb, 1000);\njest.runAllTimers();\nexpect(cb).toBeCalled();",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'jest.advanceTimersByTime(ms)'?",
        "o": [
            "Advances fake timers by specific milliseconds",
            "Moves clock forward",
            "Speeds up CPU",
            "Delays execution"
        ]
    },
    {
        "q": "What is 'Snapshot Property Matchers' syntax?",
        "o": [
            "expect.any(String), expect.any(Number)",
            "expect.string, expect.number",
            "expect.type.string",
            "expect.isString"
        ]
    },
    {
        "q": "What is 'Inline Snapshot' update mechanism?",
        "o": [
            "Jest modifies the source code file to insert the snapshot string",
            "It writes to separate file",
            "It sends email",
            "It creates git commit"
        ]
    },
    {
        "q": "What is 'Test Coverage' vs 'Test Quality'?",
        "o": [
            "Coverage = quantity logic executed; Quality = effectiveness of assertions",
            "They are same",
            "Coverage is better",
            "Quality is easier"
        ]
    },
    {
        "q": "What is 'Branch Coupling'?",
        "o": [
            "Dependency between branches of different modules",
            "Marriage of branches",
            "Git merge",
            "Tree roots"
        ]
    },
    {
        "q": "What is 'Basis Path Testing'?",
        "o": [
            "White-box testing method enabling definition of basis set of execution paths",
            "Basic testing",
            "Path finding",
            "Base camping"
        ]
    },
    {
        "q": "What is 'Du-Path' (Definition-Use Path)?",
        "o": [
            "Path from definition of variable to its usage",
            "Duplicate path",
            "Dual path",
            "Dummy path"
        ]
    },
    {
        "q": "What is 'All-Uses Coverage'?",
        "o": [
            "At least one path from every definition to every use",
            "Using all variables",
            "Using all files",
            "Using all memory"
        ]
    },
    {
        "q": "What is 'Kill the Mutants'?",
        "o": [
            "Process of eliminating code mutations by test failure",
            "Video game",
            "Debugging",
            "Refactoring"
        ]
    },
    {
        "q": "What is 'Code Instrumentation'?",
        "o": [
            "Evaluating performance or behavior by inserting trace code (profilers/coverage)",
            "Playing music",
            "Installing instruments",
            "Tuning engine"
        ]
    },
    {
        "q": "How does Istanbul instrument code?",
        "o": [
            "Inserts counters at statements/branches in the AST during compilation/transpilation",
            "Runs magic",
            "Uses camera",
            "Reads mind"
        ]
    },
    {
        "q": "What is 'Source Map' role in Coverage?",
        "o": [
            "Maps coverage data from transpiled code back to original source lines",
            "Map of the world",
            "Network map",
            "Memory map"
        ]
    },
    {
        "q": "What is 'LCOV' format?",
        "o": [
            "Standard file format for coverage data tracefiles",
            "Image format",
            "Video format",
            "Audio format"
        ]
    },
    {
        "q": "What is 'Clover' format?",
        "o": [
            "XML format for coverage, originally from Atlassian",
            "A plant",
            "A luck symbol",
            "A rabbit"
        ]
    },
    {
        "q": "What is 'Jacoco'?",
        "o": [
            "Java Code Coverage library",
            "Cocoa library",
            "Javascript library",
            "JSON library"
        ]
    },
    {
        "q": "What is 'Coverage Badges'?",
        "o": [
            "SVG images in README showing % coverage",
            "Employee badges",
            "Security badges",
            "Event badges"
        ]
    },
    {
        "q": "What is 'Git Hooks' folder?",
        "o": [
            ".git/hooks",
            ".hooks",
            "hooks",
            "git_hooks"
        ]
    },
    {
        "q": "What does 'npm test' usually run?",
        "o": [
            "Script defined in package.json under 'scripts.test'",
            "Node.js",
            "Web browser",
            "Compilation"
        ]
    },
    {
        "q": "What is 'Headless Browser'?",
        "o": [
            "Web browser without a GUI (faster for testing)",
            "Browser with no brain",
            "Broken browser",
            "Text editor"
        ]
    },
    {
        "q": "What is 'Puppeteer'?",
        "o": [
            "Node library to control Headless Chrome",
            "Doll master",
            "Testing framework",
            "Database"
        ]
    },
    {
        "q": "What is 'Playwright'?",
        "o": [
            "E2E testing framework by Microsoft supporting all modern browsers",
            "Script writer",
            "Actor",
            "Theater"
        ]
    },
    {
        "q": "What is 'Visual Regression' vs 'Functional Testing'?",
        "o": [
            "Visual checks pixels; Functional checks logic/workflow",
            "They are same",
            "Visual is better",
            "Functional is better"
        ]
    },
    {
        "q": "What is 'Flaky Test' mitigation via Retries?",
        "o": [
            "Automatically retrying failed test N times (band-aid solution)",
            "Fixing root cause",
            "Deleting test",
            "Ignoring test"
        ]
    },
    {
        "q": "Is using Retries a best practice?",
        "o": [
            "No, it hides the flakiness; better to fix the root cause",
            "Yes, always",
            "Yes, saves time",
            "Depends on weather"
        ]
    },
    {
        "q": "What is 'Test Data Factory'?",
        "o": [
            "Blueprint to create test objects with default values but overridable",
            "Manufacturing plant",
            "Database",
            "API"
        ]
    },
    {
        "q": "What library provides factories in Laravel?",
        "o": [
            "Model Factories (Faker)",
            "Builders",
            "Constructors",
            "Seeds"
        ]
    },
    {
        "q": "What is 'Faker' library?",
        "o": [
            "Library to generate massive amounts of fake data (names, address, etc)",
            "Fake news",
            "Fake code",
            "Fake tests"
        ]
    },
    {
        "q": "What is 'Assertion Library' vs 'Test Runner'?",
        "o": [
            "Library defines 'expect/assert'; Runner finds and executes files",
            "They match",
            "Library runs code",
            "Runner asserts"
        ]
    },
    {
        "q": "Mocha is a _ while Chai is an _?",
        "o": [
            "Test Runner; Assertion Library",
            "Assertion Library; Test Runner",
            "Coffee; Tea",
            "Language; Framework"
        ]
    },
    {
        "q": "Jest includes both _ and _?",
        "o": [
            "Runner and Assertions (Batteries included)",
            "Frontend and Backend",
            "Database and Cache",
            "Mouse and Keyboard"
        ]
    },
    {
        "q": "What is 'Snapshot Testing' serializer?",
        "o": [
            "Formats data structure for snapshot storage (e.g. converting Enzyme wrapper to HTML)",
            "Serial killer",
            "Cereal code",
            "Number generator"
        ]
    },
    {
        "q": "What is 'Setup/Teardown' cascade?",
        "o": [
            "beforeAll(Global) -> beforeEach(Suite) -> Test -> afterEach -> afterAll",
            "Random order",
            "Test first",
            "Setup last"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "expect(NaN).toBeNaN();",
        "o": [
            "Pass",
            "Fail",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is the output of this code?",
        "c": "expect(NaN).toBe(NaN);",
        "o": [
            "Fail (in some frameworks, use toBeNaN due to NaN !== NaN)",
            "Pass",
            "Error",
            "Warning"
        ]
    },
    {
        "q": "What is 'Property Matcher' for Date?",
        "o": [
            "expect.any(Date) or expect.stringMatching(dateRegex)",
            "expect.date",
            "expect.now",
            "expect.time"
        ]
    },
    {
        "q": "What is 'Wait For' expectation?",
        "o": [
            "Polling until an expectation passes or times out",
            "Waiting forever",
            "Pause execution",
            "Sleep"
        ]
    },
    {
        "q": "What is 'waitFor' syntax in Testing Library?",
        "o": [
            "await waitFor(() => expect(...))",
            "waitFor(expect(...))",
            "await expect(...).waitFor()",
            "wait(...)"
        ]
    },
    {
        "q": "What is 'Act' function in React Testing?",
        "o": [
            "Helper to ensure updates are processed before assertions (flush effects)",
            "Action movie",
            "Actor model",
            "Acting class"
        ]
    },
    {
        "q": "What is 'Shallow Rendering'?",
        "o": [
            "Rendering a component one level deep (mocking children)",
            "Poor rendering",
            "Fast rendering",
            "Water rendering"
        ]
    },
    {
        "q": "What is 'Deep Rendering' / 'Mount'?",
        "o": [
            "Rendering full component tree including children",
            "Slow rendering",
            "Deep water",
            "Mountaineering"
        ]
    },
    {
        "q": "Why prefer 'Deep Rendering' in modern testing?",
        "o": [
            "Better reflects user experience; Shallow is too tied to implementation",
            "It is faster",
            "It is easier",
            "It uses less memory"
        ]
    },
    {
        "q": "What is 'ByRole' query preference?",
        "o": [
            "Preferred query (Accessibility oriented) - getByRole('button', ...)",
            "Lowest preference",
            "Deprecated",
            "Slow"
        ]
    },
    {
        "q": "What is 'Test Id' (data-testid)?",
        "o": [
            "Attribute for selecting elements in tests when no logical selector exists",
            "Database ID",
            "User ID",
            "CSS Class"
        ]
    },
    {
        "q": "When should you use 'Test Id'?",
        "o": [
            "As a last resort after Role, Label, Text, etc.",
            "Always first",
            "Never",
            "For styling"
        ]
    },
    {
        "q": "What is 'Invariant'?",
        "o": [
            "A rule that is true during execution of program",
            "A variable",
            "A variant",
            "A mutation"
        ]
    },
    {
        "q": "What is 'Formal Methods' in software?",
        "o": [
            "Math-based techniques for spec, dev, and verification",
            "Formal dress",
            "Method acting",
            "Standard testing"
        ]
    }
]