[
    {
        "title": "Latency vs. Throughput üèéÔ∏è",
        "ques": "In real-time systems, is it more important to have High Throughput or Low Latency? Explain the difference.",
        "answer": {
            "type": "text",
            "content": "*   **Latency:** The delay before a transfer of data begins (Response time). Low latency is **crucial** for real-time (e.g., gaming, voice chat).\n*   **Throughput:** The amount of data transferred in a period. High throughput is good for file downloads or video streaming buffer, but less critical for instant interactivity."
        },
        "explanation": "Real-time is about \"Right Now\". You'd rather receive a small packet instantly (Low Latency) than a huge packet 5 seconds later (High Throughput)."
    },
    {
        "title": "HTTP Constraints üõë",
        "ques": "Why is standard HTTP/1.1 poorly suited for real-time applications like a chat room?",
        "answer": {
            "type": "text",
            "content": "HTTP/1.1 is **Request-Response** based. The server cannot send data to the client unless the client asks for it first. \nTo get new chat messages, the client has to keep asking \"Anything new?\" (Polling), which creates latency and wastes bandwidth."
        },
        "explanation": "True real-time requires the server to push data proactively."
    },
    {
        "title": "OSI Layer üßÄ",
        "ques": "WebSockets operate over TCP. Which layer of the OSI model does the WebSocket Protocol (RFC 6455) sit at?",
        "answer": {
            "type": "text",
            "content": "It sits at the **Application Layer** (Layer 7), just like HTTP. However, it relies on TCP (Layer 4) for the underlying persistent connection."
        },
        "explanation": "WebSockets start as an HTTP request (Layer 7) and upgrade to a persistent TCP socket."
    },
    {
        "title": "Scaling Challenges ‚öñÔ∏è",
        "ques": "Scaling a standard REST API is stateless (just add more servers). Why is scaling a WebSocket server harder?",
        "answer": {
            "type": "text",
            "content": "WebSockets are **Stateful**. \nIf User A is connected to Server 1 and User B is connected to Server 2, Server 1 cannot send a message directly to User B. You need a **Pub/Sub** mechanism (like Redis) to bridge the servers."
        },
        "explanation": "The \"Connection State\" makes horizontal scaling non-trivial."
    },
    {
        "title": "UDP vs. TCP üì®",
        "ques": "WebSockets use TCP. Why do competitive multiplayer games often use **UDP** instead?",
        "answer": {
            "type": "text",
            "content": "**UDP** is faster because it doesn't guarantee delivery or order. \nIn a fast-paced game, if you miss a packet describing the player's position 100ms ago, you don't care anymore (it's old news). TCP forces you to wait for re-transmission of the lost packet, causing lag (HOL blocking)."
        },
        "explanation": "For the web (browsers), we are mostly stuck with TCP (WebSockets), though **WebRTC** uses UDP for media."
    }
]